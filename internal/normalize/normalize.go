// Package normalize provides Unicode normalization pipelines for security scanning.
// All scanning paths (DLP, response injection, tool poisoning, policy matching)
// use these functions to strip evasion techniques before pattern matching.
//
// This package is the single source of truth for normalization. Changes here
// propagate to all scanning paths automatically.
package normalize

import (
	"strings"
	"unicode"

	"golang.org/x/text/unicode/norm"
)

// InvisibleRanges defines Unicode ranges stripped from all scanning paths.
// Consolidates zero-width characters, Tags block (Pliny steganography vector),
// and variation selectors (emoji steganography vector) into a single source of
// truth. Ranges cover:
//   - Soft hyphen, zero-width space through RTL mark, word joiner group, BOM
//   - Variation selectors 1-16 (U+FE00-FE0F): emoji glyph modifiers
//   - Tags block (U+E0000-E007F): deprecated language tags, steganography vector
//   - Variation selectors supplement (U+E0100-E01EF): extended glyph modifiers
var InvisibleRanges = &unicode.RangeTable{
	R16: []unicode.Range16{
		{Lo: 0x00AD, Hi: 0x00AD, Stride: 1}, // soft hyphen
		{Lo: 0x200B, Hi: 0x200F, Stride: 1}, // zero-width space through RTL mark
		{Lo: 0x202A, Hi: 0x202E, Stride: 1}, // bidi embedding controls (LRE/RLE/PDF/LRO/RLO)
		{Lo: 0x2060, Hi: 0x2064, Stride: 1}, // word joiner through invisible plus
		{Lo: 0x2066, Hi: 0x2069, Stride: 1}, // bidi isolate controls (LRI/RLI/FSI/PDI)
		{Lo: 0xFE00, Hi: 0xFE0F, Stride: 1}, // variation selectors 1-16
		{Lo: 0xFEFF, Hi: 0xFEFF, Stride: 1}, // BOM / ZWNBSP
		{Lo: 0xFFF9, Hi: 0xFFFB, Stride: 1}, // interlinear annotation anchors
	},
	R32: []unicode.Range32{
		{Lo: 0xE0000, Hi: 0xE007F, Stride: 1}, // Tags block
		{Lo: 0xE0100, Hi: 0xE01EF, Stride: 1}, // variation selectors supplement
	},
}

// confusableMap maps Unicode characters from non-Latin scripts that are visually
// identical to Latin letters. NFKC normalization does NOT handle cross-script
// confusables â€” Cyrillic Ğ° (U+0430) stays as Ğ°, not Latin a.
//
// Covers Cyrillic, Greek, Armenian, Cherokee, and Latin Extended (small caps/IPA)
// lookalikes commonly used in homoglyph attacks. Not exhaustive â€” focused on
// characters that appear in English-language injection phrases and DLP key prefixes.
var confusableMap = map[rune]rune{
	// Cyrillic uppercase â†’ Latin
	'\u0410': 'A', // Ğ
	'\u0412': 'B', // Ğ’
	'\u0421': 'C', // Ğ¡
	'\u0415': 'E', // Ğ•
	'\u041D': 'H', // Ğ
	'\u0406': 'I', // Ğ† (Ukrainian)
	'\u0408': 'J', // Ğˆ (Serbian)
	'\u041A': 'K', // Ğš
	'\u041C': 'M', // Ğœ
	'\u041E': 'O', // Ğ
	'\u0420': 'P', // Ğ 
	'\u0405': 'S', // Ğ… (Macedonian)
	'\u0422': 'T', // Ğ¢
	'\u0425': 'X', // Ğ¥

	// Cyrillic lowercase â†’ Latin
	'\u0430': 'a', // Ğ°
	'\u0432': 'v', // Ğ²
	'\u0435': 'e', // Ğµ
	'\u043D': 'h', // Ğ½
	'\u0456': 'i', // Ñ– (Ukrainian)
	'\u043A': 'k', // Ğº
	'\u043C': 'm', // Ğ¼
	'\u043E': 'o', // Ğ¾
	'\u0440': 'p', // Ñ€
	'\u0441': 'c', // Ñ
	'\u0442': 't', // Ñ‚
	'\u0443': 'y', // Ñƒ
	'\u0445': 'x', // Ñ…
	'\u0458': 'j', // Ñ˜ (Serbian)
	'\u0455': 's', // Ñ• (Macedonian)

	// Greek uppercase â†’ Latin
	'\u0391': 'A', // Î‘
	'\u0392': 'B', // Î’
	'\u0395': 'E', // Î•
	'\u0396': 'Z', // Î–
	'\u0397': 'H', // Î—
	'\u0399': 'I', // Î™
	'\u039A': 'K', // Îš
	'\u039C': 'M', // Îœ
	'\u039D': 'N', // Î
	'\u039F': 'O', // ÎŸ
	'\u03A1': 'P', // Î¡
	'\u03A4': 'T', // Î¤
	'\u03A5': 'Y', // Î¥
	'\u03A7': 'X', // Î§

	// Greek lowercase â†’ Latin
	'\u03B1': 'a', // Î±
	'\u03B5': 'e', // Îµ
	'\u03B9': 'i', // Î¹
	'\u03BA': 'k', // Îº
	'\u03BD': 'v', // Î½ (nu)
	'\u03BF': 'o', // Î¿

	// Armenian â†’ Latin (visually identical in most fonts)
	'\u0555': 'O', // Õ• (Armenian Capital Letter Oh)
	'\u0585': 'o', // Ö… (Armenian Small Letter Oh)
	'\u054D': 'S', // Õ (Armenian Capital Letter Seh)
	'\u057D': 's', // Õ½ (Armenian Small Letter Seh)
	'\u054C': 'L', // Ô¼ â€” not perfect but close in sans-serif
	'\u0570': 'h', // Õ° (Armenian Small Letter Ho)
	'\u0578': 'n', // Õ¸ (Armenian Small Letter Vo â€” looks like n)
	'\u057C': 'n', // Õ¼ (Armenian Small Letter Ra â€” looks like n in some fonts)
	'\u0561': 'a', // Õ¡ (Armenian Small Letter Ayb â€” similar to a in some fonts)

	// Cherokee â†’ Latin (uppercase only)
	'\u13AA': 'A', // áª (Cherokee Letter GA â€” looks like A)
	'\u13A2': 'I', // á¢ (Cherokee Letter I â€” looks like I)
	'\u13D2': 'P', // á¢
	'\u13DA': 'S', // áš
	'\u13A1': 'E', // á¡ â€” visually close to E
	'\u13B3': 'W', // á³
	'\u13D4': 'T', // á”

	// Latin Extended / IPA (small caps that survive NFKC)
	'\u1D00': 'A', // á´€ (Latin Letter Small Capital A)
	'\u0299': 'B', // Ê™ (Latin Letter Small Capital B)
	'\u1D04': 'C', // á´„ (Latin Letter Small Capital C)
	'\u1D05': 'D', // á´… (Latin Letter Small Capital D)
	'\u1D07': 'E', // á´‡ (Latin Letter Small Capital E)
	'\uA730': 'F', // êœ° (Latin Letter Small Capital F)
	'\u0262': 'G', // É¢ (Latin Letter Small Capital G)
	'\u029C': 'H', // Êœ (Latin Letter Small Capital H)
	'\u026A': 'I', // Éª (Latin Letter Small Capital I)
	'\u1D0A': 'J', // á´Š (Latin Letter Small Capital J)
	'\u1D0B': 'K', // á´‹ (Latin Letter Small Capital K)
	'\u029F': 'L', // ÊŸ (Latin Letter Small Capital L)
	'\u1D0D': 'M', // á´ (Latin Letter Small Capital M)
	'\u0274': 'N', // É´ (Latin Letter Small Capital N)
	'\u1D0F': 'O', // á´ (Latin Letter Small Capital O)
	'\u1D18': 'P', // á´˜ (Latin Letter Small Capital P)
	'\u0280': 'R', // Ê€ (Latin Letter Small Capital R)
	'\uA731': 'S', // êœ± (Latin Letter Small Capital S)
	'\u1D1B': 'T', // á´› (Latin Letter Small Capital T)
	'\u1D1C': 'U', // á´œ (Latin Letter Small Capital U)
	'\u1D20': 'V', // á´  (Latin Letter Small Capital V)
	'\u1D21': 'W', // á´¡ (Latin Letter Small Capital W)
	'\u028F': 'Y', // Ê (Latin Letter Small Capital Y)
	'\u1D22': 'Z', // á´¢ (Latin Letter Small Capital Z)

	// Negative Squared Latin Capital Letters (U+1F170â€“U+1F189)
	// Emoji-style boxed letters that LLMs read as Latin. NFKC does not decompose them.
	'\U0001F170': 'A', // ğŸ…°
	'\U0001F171': 'B', // ğŸ…±
	'\U0001F172': 'C', // ğŸ…²
	'\U0001F173': 'D', // ğŸ…³
	'\U0001F174': 'E', // ğŸ…´
	'\U0001F175': 'F', // ğŸ…µ
	'\U0001F176': 'G', // ğŸ…¶
	'\U0001F177': 'H', // ğŸ…·
	'\U0001F178': 'I', // ğŸ…¸
	'\U0001F179': 'J', // ğŸ…¹
	'\U0001F17A': 'K', // ğŸ…º
	'\U0001F17B': 'L', // ğŸ…»
	'\U0001F17C': 'M', // ğŸ…¼
	'\U0001F17D': 'N', // ğŸ…½
	'\U0001F17E': 'O', // ğŸ…¾
	'\U0001F17F': 'P', // ğŸ…¿
	'\U0001F180': 'Q', // ğŸ†€
	'\U0001F181': 'R', // ğŸ†
	'\U0001F182': 'S', // ğŸ†‚
	'\U0001F183': 'T', // ğŸ†ƒ
	'\U0001F184': 'U', // ğŸ†„
	'\U0001F185': 'V', // ğŸ†…
	'\U0001F186': 'W', // ğŸ††
	'\U0001F187': 'X', // ğŸ†‡
	'\U0001F188': 'Y', // ğŸ†ˆ
	'\U0001F189': 'Z', // ğŸ†‰

	// Regional Indicator Symbols (U+1F1E6â€“U+1F1FF)
	// Used in pairs for flag emoji (ğŸ‡ºğŸ‡¸ = U+1F1FA + U+1F1F8), but individually
	// render as circled letters that LLMs interpret as Latin characters.
	'\U0001F1E6': 'A', // ğŸ‡¦
	'\U0001F1E7': 'B', // ğŸ‡§
	'\U0001F1E8': 'C', // ğŸ‡¨
	'\U0001F1E9': 'D', // ğŸ‡©
	'\U0001F1EA': 'E', // ğŸ‡ª
	'\U0001F1EB': 'F', // ğŸ‡«
	'\U0001F1EC': 'G', // ğŸ‡¬
	'\U0001F1ED': 'H', // ğŸ‡­
	'\U0001F1EE': 'I', // ğŸ‡®
	'\U0001F1EF': 'J', // ğŸ‡¯
	'\U0001F1F0': 'K', // ğŸ‡°
	'\U0001F1F1': 'L', // ğŸ‡±
	'\U0001F1F2': 'M', // ğŸ‡²
	'\U0001F1F3': 'N', // ğŸ‡³
	'\U0001F1F4': 'O', // ğŸ‡´
	'\U0001F1F5': 'P', // ğŸ‡µ
	'\U0001F1F6': 'Q', // ğŸ‡¶
	'\U0001F1F7': 'R', // ğŸ‡·
	'\U0001F1F8': 'S', // ğŸ‡¸
	'\U0001F1F9': 'T', // ğŸ‡¹
	'\U0001F1FA': 'U', // ğŸ‡º
	'\U0001F1FB': 'V', // ğŸ‡»
	'\U0001F1FC': 'W', // ğŸ‡¼
	'\U0001F1FD': 'X', // ğŸ‡½
	'\U0001F1FE': 'Y', // ğŸ‡¾
	'\U0001F1FF': 'Z', // ğŸ‡¿
}

// NormalizeWhitespace replaces Unicode whitespace characters that Go's RE2 \s
// does not match with ASCII space.
func NormalizeWhitespace(s string) string {
	return strings.Map(func(r rune) rune {
		switch r {
		case '\u1680', '\u180E', '\u2028', '\u2029':
			return ' '
		}
		return r
	}, s)
}

// NormalizeLeetspeak maps common digit-for-letter substitutions used in
// L1B3RT4S-style injection evasion.
func NormalizeLeetspeak(s string) string {
	return strings.Map(func(r rune) rune {
		switch r {
		case '0':
			return 'o'
		case '1':
			return 'i'
		case '3':
			return 'e'
		case '4':
			return 'a'
		case '5':
			return 's'
		case '7':
			return 't'
		case '@':
			return 'a'
		case '$':
			return 's'
		}
		return r
	}, s)
}

// mapInvisible maps non-whitespace control characters and Unicode invisible
// characters to the given replacement rune. Pass -1 to strip, ' ' to replace
// with space. Whitespace controls (\t, \n, \r) are always preserved.
func mapInvisible(s string, replacement rune) string {
	return strings.Map(func(r rune) rune {
		if r <= 0x1F && r != '\t' && r != '\n' && r != '\r' {
			return replacement
		}
		if r == 0x7F {
			return replacement
		}
		if r >= 0x80 && r <= 0x9F {
			return replacement
		}
		if unicode.Is(InvisibleRanges, r) {
			return replacement
		}
		return r
	}, s)
}

// StripZeroWidth removes ASCII control characters (except \t, \n, \r) and
// Unicode zero-width/invisible characters. Preserves whitespace control chars
// because injection patterns use \s+ to match them.
// Used in response/injection scanning paths.
func StripZeroWidth(s string) string {
	return mapInvisible(s, -1)
}

// ReplaceInvisibleWithSpace replaces invisible/control characters with spaces
// instead of dropping them. Preserves word boundaries at invisible character
// positions: "ignore\u200ball" becomes "ignore all" (detectable) instead of
// "ignoreall" (bypass). Used in policy matching where word boundaries matter.
func ReplaceInvisibleWithSpace(s string) string {
	return mapInvisible(s, ' ')
}

// ConfusableToASCII maps visually identical non-Latin characters to their Latin
// equivalents. Applied after NFKC normalization to catch cross-script homoglyph
// attacks that NFKC does not handle (Cyrillic, Greek lookalikes).
func ConfusableToASCII(s string) string {
	return strings.Map(func(r rune) rune {
		if mapped, ok := confusableMap[r]; ok {
			return mapped
		}
		return r
	}, s)
}

// StripCombiningMarks removes Unicode combining marks (category Mn) that survive
// NFKC normalization. NFD decomposition reverses NFKC composition so combining
// marks can be stripped. Applied after NFKC + confusable mapping.
func StripCombiningMarks(s string) string {
	s = norm.NFD.String(s)
	return strings.Map(func(r rune) rune {
		if unicode.Is(unicode.Mn, r) {
			return -1
		}
		return r
	}, s)
}

// StripControlChars removes ALL C0 (0x00-0x1F), C1 (0x80-0x9F), DEL (0x7F),
// and Unicode zero-width/invisible characters. Unlike StripZeroWidth, this also
// strips whitespace control chars (\t, \n, \r) because DLP patterns match
// specific character sequences where ANY control char is evasion, not content.
// Used in DLP scanning paths.
func StripControlChars(s string) string {
	return strings.Map(func(r rune) rune {
		if r <= 0x1F || r == 0x7F || (r >= 0x80 && r <= 0x9F) {
			return -1
		}
		if unicode.Is(InvisibleRanges, r) {
			return -1
		}
		return r
	}, s)
}

// ForDLP applies the standard DLP normalization pipeline: strip all control/invisible
// characters, NFKC decomposition, confusable-to-ASCII mapping, combining mark removal.
// Used across all DLP scanning paths (URL segments, MCP text, env leak detection).
func ForDLP(s string) string {
	s = StripControlChars(s)
	s = norm.NFKC.String(s)
	s = ConfusableToASCII(s)
	s = StripCombiningMarks(s)
	return s
}

// ForMatching applies the standard normalization pipeline for response/injection
// scanning: strip invisible chars (preserve whitespace), NFKC, confusable mapping,
// combining mark removal, whitespace normalization.
func ForMatching(s string) string {
	s = StripZeroWidth(s)
	s = norm.NFKC.String(s)
	s = ConfusableToASCII(s)
	s = StripCombiningMarks(s)
	s = NormalizeWhitespace(s)
	return s
}

// ForPolicy applies the same pipeline as ForMatching, but replaces invisible
// characters with spaces instead of dropping them. This preserves word boundaries
// critical for tool-policy regex: "rm\u200b-rf" â†’ "rm -rf" (matchable).
func ForPolicy(s string) string {
	s = ReplaceInvisibleWithSpace(s)
	s = norm.NFKC.String(s)
	s = ConfusableToASCII(s)
	s = StripCombiningMarks(s)
	s = NormalizeWhitespace(s)
	return s
}

// ForToolText applies normalization for MCP tool description scanning. Strips ALL
// control chars and invisibles, then NFKC + confusable + marks + leetspeak +
// whitespace. More aggressive than ForMatching because tool descriptions have no
// legitimate control chars â€” any present are evasion attempts.
func ForToolText(s string) string {
	s = StripControlChars(s)
	s = norm.NFKC.String(s)
	s = ConfusableToASCII(s)
	s = StripCombiningMarks(s)
	s = NormalizeLeetspeak(s)
	s = NormalizeWhitespace(s)
	return s
}
